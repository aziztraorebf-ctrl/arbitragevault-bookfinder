#!/usr/bin/env python3
"""
AutoScheduler Runner - AutoSourcing planifi√© pour ArbitrageVault
Ex√©cute des recherches AutoSourcing automatiques selon horaire configur√©.
"""
import os
import sys
import asyncio
import json
import tempfile
from datetime import datetime, time
from pathlib import Path
from typing import Dict, Any, List, Optional
import keyring

# Add project root to path
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from app.core.settings import get_settings
from app.core.database import get_async_session, Base, engine
from app.services.autosourcing_service import AutoSourcingService
from app.services.autoscheduler_metrics import AutoSchedulerMetrics
from app.models.autosourcing import DiscoveryRequest, SearchConfig, SavedProfile
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
import structlog

# Configuration logging
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="ISO"),
        structlog.processors.add_log_level,
        structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.make_filtering_bound_logger(20),  # INFO level
    logger_factory=structlog.PrintLoggerFactory(),
    cache_logger_on_first_use=True,
)
logger = structlog.get_logger()

# Configuration AutoScheduler
SCHEDULE_CONFIG = {
    "enabled": os.getenv("AUTOSOURCING_ENABLED", "true").lower() == "true",
    "hours": json.loads(os.getenv("AUTOSOURCING_HOURS", "[8, 15, 20]")),
    "max_results": int(os.getenv("AUTOSOURCING_MAX_RESULTS", "45")),
    "token_budget_daily": int(os.getenv("AUTOSOURCING_TOKEN_BUDGET", "12000")),
    "bsr_max": int(os.getenv("AUTOSOURCING_BSR_MAX", "250000")),
    "profile_rotation": os.getenv("AUTOSOURCING_PROFILE_ROTATION", "true").lower() == "true",
    "lock_file": "/tmp/autoscheduler.lock"
}

class AutoSchedulerRunner:
    """Gestionnaire principal de l'AutoScheduler"""
    
    def __init__(self):
        self.metrics = AutoSchedulerMetrics()
        self.lock_file = Path(SCHEDULE_CONFIG["lock_file"])
        
    def is_running(self) -> bool:
        """V√©rifie si l'AutoScheduler est d√©j√† en cours d'ex√©cution"""
        return self.lock_file.exists()
    
    def create_lock(self):
        """Cr√©e le fichier de verrou"""
        try:
            self.lock_file.write_text(str(os.getpid()))
            logger.info("üîí Lock file cr√©√©")
        except Exception as e:
            logger.error(f"Erreur cr√©ation lock file: {e}")
            raise
    
    def remove_lock(self):
        """Supprime le fichier de verrou"""
        try:
            if self.lock_file.exists():
                self.lock_file.unlink()
                logger.info("üîì Lock file supprim√©")
        except Exception as e:
            logger.warning(f"Erreur suppression lock file: {e}")
    
    def should_run_now(self) -> bool:
        """D√©termine si un run doit √™tre ex√©cut√© maintenant"""
        if not SCHEDULE_CONFIG["enabled"]:
            logger.info("AutoScheduler d√©sactiv√© via configuration")
            return False
        
        current_hour = datetime.now().hour
        scheduled_hours = SCHEDULE_CONFIG["hours"]
        
        should_run = current_hour in scheduled_hours
        
        if should_run:
            logger.info(f"‚úÖ Heure de run d√©tect√©e: {current_hour}h (programm√©: {scheduled_hours})")
        else:
            logger.debug(f"‚è∞ Pas l'heure de run: {current_hour}h (programm√©: {scheduled_hours})")
        
        return should_run
    
    def get_search_criteria_for_hour(self, hour: int) -> Dict[str, Any]:
        """G√©n√®re les crit√®res de recherche diversifi√©s selon l'heure"""
        if not SCHEDULE_CONFIG["profile_rotation"]:
            # Profil standard si rotation d√©sactiv√©e
            return {
                "categories": ["Books"],
                "price_range": {"min": 15, "max": 50},
                "bsr_range": {"min": 1000, "max": 150000}
            }
        
        # Profils diversifi√©s par heure
        hour_profiles = {
            8: {  # Matin: Conservateur
                "categories": ["Books"],
                "price_range": {"min": 10, "max": 35},
                "bsr_range": {"min": 1000, "max": 75000}
            },
            15: {  # Midi: √âquilibr√©
                "categories": ["Books"],
                "price_range": {"min": 15, "max": 50},
                "bsr_range": {"min": 1000, "max": 150000}
            },
            20: {  # Soir: Agressif + Large BSR
                "categories": ["Books"],
                "price_range": {"min": 20, "max": 60},
                "bsr_range": {"min": 1000, "max": SCHEDULE_CONFIG["bsr_max"]}
            }
        }
        
        profile = hour_profiles.get(hour, hour_profiles[15])  # Default √† midi
        logger.info(f"üìä Profil {hour}h: Prix ${profile['price_range']['min']}-{profile['price_range']['max']}, BSR ‚â§{profile['bsr_range']['max']}")
        
        return profile
    
    async def run_autoscheduler(self) -> Optional[Dict[str, Any]]:
        """
        Ex√©cute un cycle AutoScheduler complet.
        
        Returns:
            R√©sum√© du run ou None si erreur
        """
        current_hour = datetime.now().hour
        
        # V√©rification budget tokens
        if not self.metrics.check_token_budget(SCHEDULE_CONFIG["token_budget_daily"]):
            logger.warning("üö´ Budget tokens quotidien √©puis√© - skip run")
            return None
        
        # Cr√©ation de la session database
        async with get_async_session() as db:
            try:
                autosourcing_service = AutoSourcingService(db)
                
                # G√©n√©ration crit√®res de recherche diversifi√©s
                search_criteria = self.get_search_criteria_for_hour(current_hour)
                max_results = SCHEDULE_CONFIG["max_results"]
                
                # Configuration de recherche
                search_config = SearchConfig(
                    categories=search_criteria["categories"],
                    price_range_min=float(search_criteria["price_range"]["min"]),
                    price_range_max=float(search_criteria["price_range"]["max"]),
                    bsr_threshold=search_criteria["bsr_range"]["max"],
                    profit_margin_min=0.25,  # 25% minimum
                    roi_threshold=0.30       # 30% ROI minimum
                )
                
                # Requ√™te de d√©couverte
                discovery_request = DiscoveryRequest(
                    name=f"AutoScheduler {current_hour}h - {datetime.now().strftime('%Y-%m-%d')}",
                    search_config=search_config,
                    max_products=max_results,
                    scheduler_run_id=f"auto_{datetime.now().strftime('%Y%m%d_%H%M')}"
                )
                
                logger.info(f"üöÄ D√©marrage AutoScheduler {current_hour}h - {max_results} produits max")
                self.metrics.record_run_start(current_hour, max_results)
                
                # Ex√©cution de la recherche
                job_result = await autosourcing_service.discover_products(discovery_request)
                
                # Extraction des produits avec tiers
                products_with_tiers = []
                tokens_estimated = 0  # TODO: r√©cup√©rer vrais tokens depuis KeepaService
                
                for pick in job_result.discovered_products:
                    product_data = {
                        "asin": pick.asin,
                        "title": pick.title,
                        "profit_net": pick.profit_net,
                        "roi_percentage": pick.roi_percentage,
                        "priority_tier": pick.priority_tier,
                        "tier_reason": pick.tier_reason,
                        "is_featured": pick.is_featured,
                        "bsr": pick.bsr,
                        "overall_rating": pick.overall_rating,
                        "created_at": pick.created_at.isoformat()
                    }
                    products_with_tiers.append(product_data)
                
                # Estimation tokens (approximative bas√©e sur produits trouv√©s)
                tokens_estimated = len(products_with_tiers) * 25  # ~25 tokens par produit
                
                # Enregistrement m√©triques
                self.metrics.record_run_completion(products_with_tiers, tokens_estimated, current_hour)
                
                # R√©sum√© du run
                run_summary = {
                    "hour": current_hour,
                    "job_id": str(job_result.id),
                    "products_found": len(products_with_tiers),
                    "tokens_estimated": tokens_estimated,
                    "tier_distribution": self._count_tiers(products_with_tiers),
                    "top_opportunities": self._get_top_opportunities(products_with_tiers, 3),
                    "status": "success",
                    "timestamp": datetime.now().isoformat()
                }
                
                logger.info(f"‚úÖ AutoScheduler {current_hour}h termin√©", extra={"run_summary": run_summary})
                return run_summary
                
            except Exception as e:
                self.metrics.record_error("run_execution", str(e))
                logger.error(f"‚ùå Erreur AutoScheduler: {e}")
                return None
    
    def _count_tiers(self, products: List[Dict]) -> Dict[str, int]:
        """Compte la distribution des tiers"""
        tiers = {"HOT": 0, "TOP": 0, "WATCH": 0, "OTHER": 0}
        for product in products:
            tier = product.get("priority_tier", "OTHER")
            if tier in tiers:
                tiers[tier] += 1
        return tiers
    
    def _get_top_opportunities(self, products: List[Dict], limit: int = 3) -> List[Dict]:
        """R√©cup√®re les top opportunit√©s par ROI"""
        sorted_products = sorted(products, key=lambda p: p.get("roi_percentage", 0), reverse=True)
        return [{
            "asin": p["asin"], 
            "title": p["title"][:60] + "..." if len(p["title"]) > 60 else p["title"],
            "roi": p["roi_percentage"],
            "tier": p["priority_tier"]
        } for p in sorted_products[:limit]]

async def main():
    """Point d'entr√©e principal"""
    runner = AutoSchedulerRunner()
    
    logger.info("üéØ AutoScheduler d√©marr√©", extra={"config": SCHEDULE_CONFIG})
    
    # V√©rification lock file
    if runner.is_running():
        logger.warning("‚ö†Ô∏è AutoScheduler d√©j√† en cours - abandon")
        return
    
    # V√©rification horaire
    if not runner.should_run_now():
        logger.info("‚è≥ Pas l'heure de run - arr√™t")
        return
    
    # Ex√©cution avec protection lock
    try:
        runner.create_lock()
        
        # Run principal
        result = await runner.run_autoscheduler()
        
        if result:
            logger.info("üéâ AutoScheduler termin√© avec succ√®s")
            
            # Log r√©sum√© quotidien
            daily_summary = runner.metrics.log_daily_summary()
            print("\nüìä R√âSUM√â QUOTIDIEN:")
            for key, value in daily_summary.items():
                print(f"  {key}: {value}")
        else:
            logger.warning("‚ö†Ô∏è AutoScheduler termin√© sans r√©sultat")
    
    except Exception as e:
        logger.error(f"üí• Erreur critique AutoScheduler: {e}")
        
    finally:
        runner.remove_lock()

if __name__ == "__main__":
    asyncio.run(main())