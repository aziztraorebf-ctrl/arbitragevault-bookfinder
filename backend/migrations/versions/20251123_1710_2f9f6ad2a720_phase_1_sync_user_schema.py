"""phase_1_sync_user_schema

Revision ID: 2f9f6ad2a720
Revises: phase_8_0_analytics
Create Date: 2025-11-23 17:10:44.002176

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '2f9f6ad2a720'
down_revision = 'phase_8_0_analytics'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###

    # CRITICAL FIX: Convert keepa_products.id to UUID BEFORE creating tables with FK to it
    # Step 1: Drop server_default first (PostgreSQL cannot cast default to UUID)
    op.alter_column('keepa_products', 'id',
               existing_type=sa.VARCHAR(length=36),
               server_default=None,
               existing_nullable=False)

    # Step 2: Convert to UUID with USING clause
    op.alter_column('keepa_products', 'id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='id::uuid')

    # CRITICAL FIX: Handle chicken-and-egg problem with ALL FKs to users.id
    # Step 1: Drop ALL FK constraints to users.id temporarily
    op.drop_constraint('batches_user_id_fkey', 'batches', type_='foreignkey')
    op.drop_constraint('saved_niches_user_id_fkey', 'saved_niches', type_='foreignkey')

    # Step 2: Clean invalid test data from users table first
    # This will orphan related records in batches/saved_niches, which we'll clean next
    op.execute("DELETE FROM users WHERE id NOT SIMILAR TO '[0-9a-f-]{36}'")

    # Step 3: Clean orphaned records in child tables
    op.execute("DELETE FROM batches WHERE user_id NOT SIMILAR TO '[0-9a-f-]{36}'")
    op.execute("DELETE FROM saved_niches WHERE user_id NOT SIMILAR TO '[0-9a-f-]{36}'")

    # Step 4: Convert users.id to UUID FIRST (drop default, then convert)
    op.alter_column('users', 'id',
               existing_type=sa.VARCHAR(length=36),
               server_default=None,
               existing_nullable=False)

    op.alter_column('users', 'id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='id::uuid')

    # Step 5: Convert FK columns to UUID
    op.alter_column('batches', 'user_id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='user_id::uuid')

    op.alter_column('saved_niches', 'user_id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='user_id::uuid')

    # Step 6: Recreate FK constraints now that all columns are UUID
    op.create_foreign_key('batches_user_id_fkey', 'batches', 'users',
                         ['user_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key('saved_niches_user_id_fkey', 'saved_niches', 'users',
                         ['user_id'], ['id'], ondelete='CASCADE')

    # Now safe to create tables with UUID FK to keepa_products.id and users.id
    op.create_table('identifier_resolution_log',
    sa.Column('original_identifier', sa.String(length=20), nullable=False),
    sa.Column('identifier_type', sa.String(length=10), nullable=False),
    sa.Column('resolved_asin', sa.String(length=10), nullable=True),
    sa.Column('resolution_status', sa.String(length=20), nullable=False),
    sa.Column('keepa_product_code', sa.Integer(), nullable=True),
    sa.Column('keepa_domain', sa.Integer(), nullable=False),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('attempted_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_identifier_resolution_log_original_identifier'), 'identifier_resolution_log', ['original_identifier'], unique=False)
    op.create_index(op.f('ix_identifier_resolution_log_resolved_asin'), 'identifier_resolution_log', ['resolved_asin'], unique=False)
    op.create_table('keepa_snapshots',
    sa.Column('product_id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('snapshot_date', sa.DateTime(timezone=True), nullable=False),
    sa.Column('data_window_days', sa.Integer(), nullable=False),
    sa.Column('current_buybox_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('current_amazon_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('current_fba_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('current_fbm_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('current_bsr', sa.Integer(), nullable=True),
    sa.Column('raw_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('metrics_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('offers_count', sa.Integer(), nullable=True),
    sa.Column('buybox_seller_type', sa.String(length=20), nullable=True),
    sa.Column('is_prime_eligible', sa.String(length=10), nullable=True),
    sa.Column('id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['product_id'], ['keepa_products.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_keepa_snapshots_current_bsr'), 'keepa_snapshots', ['current_bsr'], unique=False)
    op.create_index(op.f('ix_keepa_snapshots_product_id'), 'keepa_snapshots', ['product_id'], unique=False)
    op.create_index(op.f('ix_keepa_snapshots_snapshot_date'), 'keepa_snapshots', ['snapshot_date'], unique=False)
    op.create_table('refresh_tokens',
    sa.Column('user_id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('token_hash', sa.Text(), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('is_revoked', sa.Boolean(), nullable=False),
    sa.Column('revoked_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('ip_address', sa.String(length=45), nullable=True),
    sa.Column('user_agent', sa.Text(), nullable=True),
    sa.Column('last_used_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_refresh_tokens_token_hash'), 'refresh_tokens', ['token_hash'], unique=True)
    op.create_index(op.f('ix_refresh_tokens_user_id'), 'refresh_tokens', ['user_id'], unique=False)
    op.create_table('calc_metrics',
    sa.Column('product_id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('snapshot_id', sa.UUID(as_uuid=False), nullable=True),
    sa.Column('estimated_sell_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('estimated_buy_cost', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('amazon_fees_total', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('net_profit', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('roi_percentage', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('margin_percentage', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('referral_fee', sa.Numeric(precision=8, scale=2), nullable=True),
    sa.Column('closing_fee', sa.Numeric(precision=8, scale=2), nullable=True),
    sa.Column('fba_fee', sa.Numeric(precision=8, scale=2), nullable=True),
    sa.Column('inbound_shipping', sa.Numeric(precision=8, scale=2), nullable=True),
    sa.Column('prep_fee', sa.Numeric(precision=8, scale=2), nullable=True),
    sa.Column('target_buy_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('breakeven_price', sa.Numeric(precision=10, scale=2), nullable=True),
    sa.Column('velocity_score', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('rank_percentile_30d', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('rank_drops_30d', sa.Integer(), nullable=True),
    sa.Column('buybox_uptime_30d', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('offers_volatility', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('demand_consistency', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('price_volatility', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('competition_level', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('fee_config_used', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('calculation_params', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('calculated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('calculation_version', sa.String(length=10), nullable=False),
    sa.Column('id', sa.UUID(as_uuid=False), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['product_id'], ['keepa_products.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['snapshot_id'], ['keepa_snapshots.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_calc_metrics_net_profit'), 'calc_metrics', ['net_profit'], unique=False)
    op.create_index(op.f('ix_calc_metrics_product_id'), 'calc_metrics', ['product_id'], unique=False)
    op.create_index(op.f('ix_calc_metrics_roi_percentage'), 'calc_metrics', ['roi_percentage'], unique=False)
    op.create_index(op.f('ix_calc_metrics_snapshot_id'), 'calc_metrics', ['snapshot_id'], unique=False)
    op.create_index(op.f('ix_calc_metrics_velocity_score'), 'calc_metrics', ['velocity_score'], unique=False)
    op.drop_index(op.f('idx_decision_outcome_asin'), table_name='decision_outcomes')
    op.drop_index(op.f('idx_decision_outcome_created_at'), table_name='decision_outcomes')
    op.drop_index(op.f('idx_decision_outcome_decision'), table_name='decision_outcomes')
    op.drop_table('decision_outcomes')
    op.drop_index(op.f('idx_autosourcing_picks_action_status'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_asin'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_confidence'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_created_at'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_is_favorite'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_is_featured'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_is_ignored'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_is_purchased'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_job_id'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_overall_rating'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_priority_tier'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_roi'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_scheduler_run_id'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_stability'), table_name='autosourcing_picks')
    op.drop_index(op.f('idx_autosourcing_picks_velocity'), table_name='autosourcing_picks')
    op.drop_table('autosourcing_picks')
    op.drop_index(op.f('idx_history_created_at'), table_name='search_history')
    op.drop_index(op.f('idx_history_search_type'), table_name='search_history')
    op.drop_index(op.f('idx_history_user_id'), table_name='search_history')
    op.drop_table('search_history')
    op.drop_index(op.f('idx_discovery_created_at'), table_name='product_discovery_cache')
    op.drop_index(op.f('idx_discovery_expires_at'), table_name='product_discovery_cache')
    op.drop_table('product_discovery_cache')
    op.drop_index(op.f('idx_asin_history_asin'), table_name='asin_history')
    op.drop_index(op.f('idx_asin_history_asin_tracked'), table_name='asin_history')
    op.drop_index(op.f('idx_asin_history_tracked_at'), table_name='asin_history')
    op.drop_index(op.f('ix_asin_history_asin'), table_name='asin_history')
    op.drop_table('asin_history')
    op.drop_index(op.f('idx_autosourcing_jobs_launched_at'), table_name='autosourcing_jobs')
    op.drop_index(op.f('idx_autosourcing_jobs_profile_name'), table_name='autosourcing_jobs')
    op.drop_index(op.f('idx_autosourcing_jobs_status'), table_name='autosourcing_jobs')
    op.drop_table('autosourcing_jobs')
    op.drop_index(op.f('idx_scoring_cache_asin_expiry'), table_name='product_scoring_cache')
    op.drop_index(op.f('idx_scoring_cache_recommendation'), table_name='product_scoring_cache')
    op.drop_index(op.f('idx_scoring_cache_roi'), table_name='product_scoring_cache')
    op.drop_table('product_scoring_cache')
    op.drop_index(op.f('idx_saved_profiles_active'), table_name='saved_profiles')
    op.drop_index(op.f('idx_saved_profiles_created'), table_name='saved_profiles')
    op.drop_index(op.f('idx_saved_profiles_last_used'), table_name='saved_profiles')
    op.drop_index(op.f('idx_saved_profiles_name'), table_name='saved_profiles')
    op.drop_table('saved_profiles')
    op.drop_index(op.f('idx_run_history_executed_at'), table_name='run_history')
    op.drop_index(op.f('idx_run_history_job_id'), table_name='run_history')
    op.drop_table('run_history')
    op.alter_column('analyses', 'profit',
               existing_type=sa.NUMERIC(precision=12, scale=2),
               nullable=False)
    op.alter_column('analyses', 'roi_percent',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               type_=sa.Numeric(precision=6, scale=2),
               nullable=False)
    op.alter_column('analyses', 'velocity_score',
               existing_type=sa.NUMERIC(precision=6, scale=2),
               server_default=None,
               existing_nullable=False)
    # Split into two steps: drop default first, then convert type
    op.alter_column('analyses', 'id',
               existing_type=sa.VARCHAR(length=36),
               server_default=None,
               existing_nullable=False)
    op.alter_column('analyses', 'id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='id::uuid')
    op.alter_column('analyses', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('analyses', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))

    # CRITICAL FIX: Handle analyses.batch_id FK to batches.id (same chicken-and-egg problem)
    # Step 1: Drop FK constraint temporarily
    op.drop_constraint('analyses_batch_id_fkey', 'analyses', type_='foreignkey')

    # Step 2: Clean invalid test data (non-UUID values in batch_id)
    op.execute("DELETE FROM analyses WHERE batch_id NOT SIMILAR TO '[0-9a-f-]{36}'")

    op.create_index('ix_analyses_batch_id', 'analyses', ['batch_id'], unique=False)
    op.create_index('ix_analyses_isbn', 'analyses', ['isbn_or_asin'], unique=False)
    op.create_index('ix_analyses_roi', 'analyses', ['roi_percent'], unique=False)
    op.create_index('ix_analyses_velocity', 'analyses', ['velocity_score'], unique=False)
    op.create_unique_constraint('uq_analysis_batch_isbn', 'analyses', ['batch_id', 'isbn_or_asin'])
    op.alter_column('batches', 'status',
               existing_type=postgresql.ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', 'CANCELLED', name='batch_status'),
               server_default=None,
               existing_nullable=False)
    op.alter_column('batches', 'items_total',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
    op.alter_column('batches', 'items_processed',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
    # Split into two steps: drop default first, then convert type
    op.alter_column('batches', 'id',
               existing_type=sa.VARCHAR(length=36),
               server_default=None,
               existing_nullable=False)
    op.alter_column('batches', 'id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='id::uuid')
    op.alter_column('batches', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('batches', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))

    # Step 3: Convert analyses.batch_id to UUID now that batches.id is UUID
    op.alter_column('analyses', 'batch_id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='batch_id::uuid')

    # Step 4: Recreate FK constraint now that both columns are UUID
    op.create_foreign_key('analyses_batch_id_fkey', 'analyses', 'batches',
                         ['batch_id'], ['id'], ondelete='CASCADE')

    op.create_index('ix_batches_status', 'batches', ['status'], unique=False)
    op.create_index('ix_batches_user_created', 'batches', ['user_id', 'created_at'], unique=False)
    # config_changes.id already has no server_default, just need USING clause
    op.alter_column('config_changes', 'id',
               existing_type=sa.VARCHAR(),
               type_=sa.UUID(as_uuid=False),
               existing_nullable=False,
               postgresql_using='id::uuid')
    op.add_column('keepa_products', sa.Column('category', sa.String(length=100), nullable=True))
    op.add_column('keepa_products', sa.Column('brand', sa.String(length=200), nullable=True))
    op.add_column('keepa_products', sa.Column('manufacturer', sa.String(length=200), nullable=True))
    op.add_column('keepa_products', sa.Column('package_height', sa.Numeric(precision=10, scale=2), nullable=True))
    op.add_column('keepa_products', sa.Column('package_length', sa.Numeric(precision=10, scale=2), nullable=True))
    op.add_column('keepa_products', sa.Column('package_width', sa.Numeric(precision=10, scale=2), nullable=True))
    op.add_column('keepa_products', sa.Column('package_weight', sa.Numeric(precision=10, scale=3), nullable=True))
    op.add_column('keepa_products', sa.Column('status', sa.String(length=20), nullable=False))
    op.add_column('keepa_products', sa.Column('domain', sa.Integer(), nullable=False))
    op.add_column('keepa_products', sa.Column('original_identifier', sa.String(length=20), nullable=True))
    op.add_column('keepa_products', sa.Column('identifier_type', sa.String(length=10), nullable=True))
    op.add_column('keepa_products', sa.Column('last_keepa_sync', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('keepa_products', 'asin',
               existing_type=sa.VARCHAR(length=20),
               type_=sa.String(length=10),
               existing_nullable=False)
    op.alter_column('keepa_products', 'title',
               existing_type=sa.VARCHAR(length=500),
               type_=sa.Text(),
               existing_nullable=True)
    # NOTE: keepa_products.id conversion to UUID already done at start of upgrade()
    op.alter_column('keepa_products', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('keepa_products', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_constraint(op.f('keepa_products_asin_key'), 'keepa_products', type_='unique')
    op.create_index(op.f('ix_keepa_products_asin'), 'keepa_products', ['asin'], unique=True)
    op.drop_column('keepa_products', 'current_rank')
    op.drop_column('keepa_products', 'current_price')
    op.drop_column('keepa_products', 'category_tree')
    op.alter_column('saved_niches', 'niche_name',
               existing_type=sa.VARCHAR(length=255),
               comment="User-defined name for the niche (e.g., 'Engineering Textbooks')",
               existing_comment='User-defined name for the niche',
               existing_nullable=False)
    op.alter_column('saved_niches', 'category_id',
               existing_type=sa.INTEGER(),
               comment='Keepa category ID used for the niche discovery',
               existing_comment='Keepa category ID used for niche discovery',
               existing_nullable=True)
    op.alter_column('saved_niches', 'filters',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               server_default=None,
               comment='Complete analysis parameters (price ranges, BSR thresholds, etc.)',
               existing_comment='Complete analysis parameters',
               existing_nullable=False)
    op.alter_column('saved_niches', 'last_score',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Last calculated niche score when discovered',
               existing_comment='Last calculated niche score',
               existing_nullable=True)
    op.alter_column('saved_niches', 'description',
               existing_type=sa.TEXT(),
               comment='Optional user description or notes about the niche',
               existing_comment='Optional user notes',
               existing_nullable=True)
    op.alter_column('saved_niches', 'id',
               existing_type=sa.UUID(),
               server_default=None,
               existing_nullable=False)
    op.drop_index(op.f('ix_saved_niches_user_created'), table_name='saved_niches')
    op.add_column('users', sa.Column('role', sa.String(length=20), nullable=False))
    op.add_column('users', sa.Column('is_verified', sa.Boolean(), nullable=False))
    op.add_column('users', sa.Column('last_login_at', sa.DateTime(timezone=True), nullable=True))
    op.add_column('users', sa.Column('password_changed_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False))
    op.add_column('users', sa.Column('failed_login_attempts', sa.Integer(), nullable=False))
    op.add_column('users', sa.Column('locked_until', sa.DateTime(timezone=True), nullable=True))
    op.add_column('users', sa.Column('verification_token', sa.String(length=255), nullable=True))
    op.add_column('users', sa.Column('verification_token_expires_at', sa.DateTime(timezone=True), nullable=True))
    op.add_column('users', sa.Column('reset_token', sa.String(length=255), nullable=True))
    op.add_column('users', sa.Column('reset_token_expires_at', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('users', 'password_hash',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.Text(),
               nullable=False)
    op.alter_column('users', 'is_active',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               nullable=False)
    # NOTE: users.id conversion to UUID already done at start of upgrade()
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('users', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_constraint(op.f('users_email_key'), 'users', type_='unique')
    op.drop_constraint(op.f('users_username_key'), 'users', type_='unique')
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.drop_column('users', 'username')
    op.drop_column('users', 'is_superuser')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('users', sa.Column('is_superuser', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('username', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.create_unique_constraint(op.f('users_username_key'), 'users', ['username'], postgresql_nulls_not_distinct=False)
    op.create_unique_constraint(op.f('users_email_key'), 'users', ['email'], postgresql_nulls_not_distinct=False)
    op.alter_column('users', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('users', 'id',
               existing_type=sa.UUID(as_uuid=False),
               server_default=sa.text('(gen_random_uuid())::text'),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)
    op.alter_column('users', 'is_active',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('true'),
               nullable=True)
    op.alter_column('users', 'password_hash',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(length=255),
               nullable=True)
    op.drop_column('users', 'reset_token_expires_at')
    op.drop_column('users', 'reset_token')
    op.drop_column('users', 'verification_token_expires_at')
    op.drop_column('users', 'verification_token')
    op.drop_column('users', 'locked_until')
    op.drop_column('users', 'failed_login_attempts')
    op.drop_column('users', 'password_changed_at')
    op.drop_column('users', 'last_login_at')
    op.drop_column('users', 'is_verified')
    op.drop_column('users', 'role')
    op.create_index(op.f('ix_saved_niches_user_created'), 'saved_niches', ['user_id', 'created_at'], unique=False)
    op.alter_column('saved_niches', 'id',
               existing_type=sa.UUID(),
               server_default=sa.text('gen_random_uuid()'),
               existing_nullable=False)
    op.alter_column('saved_niches', 'description',
               existing_type=sa.TEXT(),
               comment='Optional user notes',
               existing_comment='Optional user description or notes about the niche',
               existing_nullable=True)
    op.alter_column('saved_niches', 'last_score',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Last calculated niche score',
               existing_comment='Last calculated niche score when discovered',
               existing_nullable=True)
    op.alter_column('saved_niches', 'filters',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               server_default=sa.text("'{}'::jsonb"),
               comment='Complete analysis parameters',
               existing_comment='Complete analysis parameters (price ranges, BSR thresholds, etc.)',
               existing_nullable=False)
    op.alter_column('saved_niches', 'category_id',
               existing_type=sa.INTEGER(),
               comment='Keepa category ID used for niche discovery',
               existing_comment='Keepa category ID used for the niche discovery',
               existing_nullable=True)
    op.alter_column('saved_niches', 'niche_name',
               existing_type=sa.VARCHAR(length=255),
               comment='User-defined name for the niche',
               existing_comment="User-defined name for the niche (e.g., 'Engineering Textbooks')",
               existing_nullable=False)
    op.add_column('keepa_products', sa.Column('category_tree', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('keepa_products', sa.Column('current_price', sa.NUMERIC(precision=12, scale=2), autoincrement=False, nullable=True))
    op.add_column('keepa_products', sa.Column('current_rank', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_keepa_products_asin'), table_name='keepa_products')
    op.create_unique_constraint(op.f('keepa_products_asin_key'), 'keepa_products', ['asin'], postgresql_nulls_not_distinct=False)
    op.alter_column('keepa_products', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('keepa_products', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('keepa_products', 'id',
               existing_type=sa.UUID(as_uuid=False),
               server_default=sa.text('(gen_random_uuid())::text'),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)
    op.alter_column('keepa_products', 'title',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(length=500),
               existing_nullable=True)
    op.alter_column('keepa_products', 'asin',
               existing_type=sa.String(length=10),
               type_=sa.VARCHAR(length=20),
               existing_nullable=False)
    op.drop_column('keepa_products', 'last_keepa_sync')
    op.drop_column('keepa_products', 'identifier_type')
    op.drop_column('keepa_products', 'original_identifier')
    op.drop_column('keepa_products', 'domain')
    op.drop_column('keepa_products', 'status')
    op.drop_column('keepa_products', 'package_weight')
    op.drop_column('keepa_products', 'package_width')
    op.drop_column('keepa_products', 'package_length')
    op.drop_column('keepa_products', 'package_height')
    op.drop_column('keepa_products', 'manufacturer')
    op.drop_column('keepa_products', 'brand')
    op.drop_column('keepa_products', 'category')
    op.alter_column('config_changes', 'id',
               existing_type=sa.UUID(as_uuid=False),
               type_=sa.VARCHAR(),
               existing_nullable=False)
    op.drop_index('ix_batches_user_created', table_name='batches')
    op.drop_index('ix_batches_status', table_name='batches')
    op.alter_column('batches', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('batches', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('batches', 'id',
               existing_type=sa.UUID(as_uuid=False),
               server_default=sa.text('(gen_random_uuid())::text'),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)
    op.alter_column('batches', 'items_processed',
               existing_type=sa.INTEGER(),
               server_default=sa.text('0'),
               existing_nullable=False)
    op.alter_column('batches', 'items_total',
               existing_type=sa.INTEGER(),
               server_default=sa.text('0'),
               existing_nullable=False)
    op.alter_column('batches', 'status',
               existing_type=postgresql.ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', 'CANCELLED', name='batch_status'),
               server_default=sa.text("'PENDING'::batch_status"),
               existing_nullable=False)
    op.drop_constraint('uq_analysis_batch_isbn', 'analyses', type_='unique')
    op.drop_index('ix_analyses_velocity', table_name='analyses')
    op.drop_index('ix_analyses_roi', table_name='analyses')
    op.drop_index('ix_analyses_isbn', table_name='analyses')
    op.drop_index('ix_analyses_batch_id', table_name='analyses')
    op.alter_column('analyses', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('analyses', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('analyses', 'id',
               existing_type=sa.UUID(as_uuid=False),
               server_default=sa.text('(gen_random_uuid())::text'),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)
    op.alter_column('analyses', 'velocity_score',
               existing_type=sa.NUMERIC(precision=6, scale=2),
               server_default=sa.text('0'),
               existing_nullable=False)
    op.alter_column('analyses', 'roi_percent',
               existing_type=sa.Numeric(precision=6, scale=2),
               type_=sa.NUMERIC(precision=5, scale=2),
               nullable=True)
    op.alter_column('analyses', 'profit',
               existing_type=sa.NUMERIC(precision=12, scale=2),
               nullable=True)
    op.create_table('run_history',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('job_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('config_snapshot', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('total_products_discovered', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('total_picks_generated', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('success_rate', sa.NUMERIC(precision=5, scale=2), autoincrement=False, nullable=True),
    sa.Column('tokens_consumed', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('execution_time_seconds', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('executed_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('run_history_pkey'))
    )
    op.create_index(op.f('idx_run_history_job_id'), 'run_history', ['job_id'], unique=False)
    op.create_index(op.f('idx_run_history_executed_at'), 'run_history', ['executed_at'], unique=False)
    op.create_table('saved_profiles',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('discovery_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('scoring_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('max_results', sa.INTEGER(), server_default=sa.text('20'), autoincrement=False, nullable=False),
    sa.Column('active', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=False),
    sa.Column('last_used_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('usage_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='saved_profiles_pkey'),
    sa.UniqueConstraint('name', name='saved_profiles_name_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('idx_saved_profiles_name'), 'saved_profiles', ['name'], unique=False)
    op.create_index(op.f('idx_saved_profiles_last_used'), 'saved_profiles', ['last_used_at'], unique=False)
    op.create_index(op.f('idx_saved_profiles_created'), 'saved_profiles', ['created_at'], unique=False)
    op.create_index(op.f('idx_saved_profiles_active'), 'saved_profiles', ['active'], unique=False)
    op.create_table('product_scoring_cache',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('asin', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('title', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('price', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('bsr', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('roi_percent', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('velocity_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('recommendation', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('keepa_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('config_hash', sa.VARCHAR(length=64), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('expires_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('analysis_version', sa.VARCHAR(length=20), server_default=sa.text("'1.0'::character varying"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('product_scoring_cache_pkey'))
    )
    op.create_index(op.f('idx_scoring_cache_roi'), 'product_scoring_cache', ['roi_percent'], unique=False)
    op.create_index(op.f('idx_scoring_cache_recommendation'), 'product_scoring_cache', ['recommendation'], unique=False)
    op.create_index(op.f('idx_scoring_cache_asin_expiry'), 'product_scoring_cache', ['asin', 'expires_at'], unique=False)
    op.create_table('autosourcing_jobs',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('profile_name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('profile_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('launched_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('duration_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('status', postgresql.ENUM('PENDING', 'RUNNING', 'SUCCESS', 'ERROR', 'CANCELLED', name='jobstatus'), server_default=sa.text("'PENDING'::jobstatus"), autoincrement=False, nullable=False),
    sa.Column('total_tested', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('total_selected', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('discovery_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('scoring_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('error_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['profile_id'], ['saved_profiles.id'], name='autosourcing_jobs_profile_id_fkey', ondelete='SET NULL'),
    sa.PrimaryKeyConstraint('id', name='autosourcing_jobs_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('idx_autosourcing_jobs_status'), 'autosourcing_jobs', ['status'], unique=False)
    op.create_index(op.f('idx_autosourcing_jobs_profile_name'), 'autosourcing_jobs', ['profile_name'], unique=False)
    op.create_index(op.f('idx_autosourcing_jobs_launched_at'), 'autosourcing_jobs', ['launched_at'], unique=False)
    op.create_table('asin_history',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('asin', sa.VARCHAR(length=10), autoincrement=False, nullable=False),
    sa.Column('tracked_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('price', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True),
    sa.Column('lowest_fba_price', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True),
    sa.Column('bsr', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('seller_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('amazon_on_listing', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('fba_seller_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('extra_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('asin_history_pkey'))
    )
    op.create_index(op.f('ix_asin_history_asin'), 'asin_history', ['asin'], unique=False)
    op.create_index(op.f('idx_asin_history_tracked_at'), 'asin_history', ['tracked_at'], unique=False)
    op.create_index(op.f('idx_asin_history_asin_tracked'), 'asin_history', ['asin', 'tracked_at'], unique=False)
    op.create_index(op.f('idx_asin_history_asin'), 'asin_history', ['asin'], unique=False)
    op.create_table('product_discovery_cache',
    sa.Column('cache_key', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('asins', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False, comment='Liste des ASINs découverts'),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('expires_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False, comment='TTL 24h par défaut'),
    sa.Column('hit_count', sa.INTEGER(), autoincrement=False, nullable=False, comment='Nombre de fois que ce cache a été utilisé'),
    sa.Column('domain', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('category', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('bsr_min', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('bsr_max', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('price_min', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('price_max', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('cache_key', name=op.f('product_discovery_cache_pkey'))
    )
    op.create_index(op.f('idx_discovery_expires_at'), 'product_discovery_cache', ['expires_at'], unique=False)
    op.create_index(op.f('idx_discovery_created_at'), 'product_discovery_cache', ['created_at'], unique=False)
    op.create_table('search_history',
    sa.Column('id', sa.VARCHAR(length=36), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.VARCHAR(length=36), autoincrement=False, nullable=True, comment='Future auth - actuellement NULL'),
    sa.Column('search_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False, comment='discovery, scoring, autosourcing'),
    sa.Column('filters', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False, comment='Filtres appliqués'),
    sa.Column('results_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('source', sa.VARCHAR(length=50), autoincrement=False, nullable=True, comment='frontend, api, manual'),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('search_history_pkey'))
    )
    op.create_index(op.f('idx_history_user_id'), 'search_history', ['user_id'], unique=False)
    op.create_index(op.f('idx_history_search_type'), 'search_history', ['search_type'], unique=False)
    op.create_index(op.f('idx_history_created_at'), 'search_history', ['created_at'], unique=False)
    op.create_table('autosourcing_picks',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('job_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('asin', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('title', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('current_price', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('estimated_buy_cost', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('profit_net', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('roi_percentage', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('velocity_score', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('stability_score', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('confidence_score', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('overall_rating', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('bsr', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('category', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('readable_summary', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('action_status', postgresql.ENUM('PENDING', 'TO_BUY', 'FAVORITE', 'IGNORED', 'ANALYZING', name='actionstatus'), server_default=sa.text("'PENDING'::actionstatus"), autoincrement=False, nullable=False),
    sa.Column('action_taken_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('action_notes', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('is_purchased', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('is_favorite', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('is_ignored', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('analysis_requested', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('deep_analysis_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('priority_tier', sa.VARCHAR(length=10), server_default=sa.text("'WATCH'::character varying"), autoincrement=False, nullable=False),
    sa.Column('tier_reason', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('is_featured', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('scheduler_run_id', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['autosourcing_jobs.id'], name=op.f('autosourcing_picks_job_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('autosourcing_picks_pkey'))
    )
    op.create_index(op.f('idx_autosourcing_picks_velocity'), 'autosourcing_picks', ['velocity_score'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_stability'), 'autosourcing_picks', ['stability_score'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_scheduler_run_id'), 'autosourcing_picks', ['scheduler_run_id'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_roi'), 'autosourcing_picks', ['roi_percentage'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_priority_tier'), 'autosourcing_picks', ['priority_tier'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_overall_rating'), 'autosourcing_picks', ['overall_rating'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_job_id'), 'autosourcing_picks', ['job_id'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_is_purchased'), 'autosourcing_picks', ['is_purchased'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_is_ignored'), 'autosourcing_picks', ['is_ignored'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_is_featured'), 'autosourcing_picks', ['is_featured'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_is_favorite'), 'autosourcing_picks', ['is_favorite'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_created_at'), 'autosourcing_picks', ['created_at'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_confidence'), 'autosourcing_picks', ['confidence_score'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_asin'), 'autosourcing_picks', ['asin'], unique=False)
    op.create_index(op.f('idx_autosourcing_picks_action_status'), 'autosourcing_picks', ['action_status'], unique=False)
    op.create_table('decision_outcomes',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('asin', sa.VARCHAR(length=10), autoincrement=False, nullable=False),
    sa.Column('decision', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('predicted_roi', sa.NUMERIC(precision=5, scale=2), autoincrement=False, nullable=True),
    sa.Column('predicted_velocity', sa.NUMERIC(precision=5, scale=2), autoincrement=False, nullable=True),
    sa.Column('predicted_risk_score', sa.NUMERIC(precision=5, scale=2), autoincrement=False, nullable=True),
    sa.Column('actual_outcome', sa.VARCHAR(length=20), autoincrement=False, nullable=True),
    sa.Column('actual_roi', sa.NUMERIC(precision=5, scale=2), autoincrement=False, nullable=True),
    sa.Column('time_to_sell_days', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('outcome_date', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('notes', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('decision_outcomes_pkey'))
    )
    op.create_index(op.f('idx_decision_outcome_decision'), 'decision_outcomes', ['decision'], unique=False)
    op.create_index(op.f('idx_decision_outcome_created_at'), 'decision_outcomes', ['created_at'], unique=False)
    op.create_index(op.f('idx_decision_outcome_asin'), 'decision_outcomes', ['asin'], unique=False)
    op.drop_index(op.f('ix_calc_metrics_velocity_score'), table_name='calc_metrics')
    op.drop_index(op.f('ix_calc_metrics_snapshot_id'), table_name='calc_metrics')
    op.drop_index(op.f('ix_calc_metrics_roi_percentage'), table_name='calc_metrics')
    op.drop_index(op.f('ix_calc_metrics_product_id'), table_name='calc_metrics')
    op.drop_index(op.f('ix_calc_metrics_net_profit'), table_name='calc_metrics')
    op.drop_table('calc_metrics')
    op.drop_index(op.f('ix_refresh_tokens_user_id'), table_name='refresh_tokens')
    op.drop_index(op.f('ix_refresh_tokens_token_hash'), table_name='refresh_tokens')
    op.drop_table('refresh_tokens')
    op.drop_index(op.f('ix_keepa_snapshots_snapshot_date'), table_name='keepa_snapshots')
    op.drop_index(op.f('ix_keepa_snapshots_product_id'), table_name='keepa_snapshots')
    op.drop_index(op.f('ix_keepa_snapshots_current_bsr'), table_name='keepa_snapshots')
    op.drop_table('keepa_snapshots')
    op.drop_index(op.f('ix_identifier_resolution_log_resolved_asin'), table_name='identifier_resolution_log')
    op.drop_index(op.f('ix_identifier_resolution_log_original_identifier'), table_name='identifier_resolution_log')
    op.drop_table('identifier_resolution_log')
    # ### end Alembic commands ###